             CNN-SLAM:实时稠密单目SLAM及深度估计
【摘要】
	鉴于最近深度卷积神经网络(CNN)在深度估计方面的研究有不错的进展，这篇论文研究如何用CNN和单目相机重建出准确且稠密的三维场景。我们提出了一个方法，它可让CNN预测的稠密深度地图与单目SLAM估计的深度图自然融合。该方法在单目SLAM失效的时候（如低纹理区域）仍然能够很好地工作。我们展示了用深度预测来估计重建三维场景的绝对尺度，以解决单目SLAM无法得到绝对尺度这一主要缺陷。最后，我们提出了一个框架，它可将单幅图像中提取的语义标签和稠密SLAM高效地融合在一起，达到从单视角语义一致性地重建场景的效果。在两个数据集上的测试表明我们提出的算法有很高的准确性和很强的鲁棒性。


Migration:
Switching code to OpenCV3 can be done following the official guide at http://docs.opencv.org/master/db/dfa/tutorial_transition_guide.html. 

【引言-部分内容】
	传统SLAM有几点缺陷：
		1.工作范围小。
		2.基于主动感知的SLAM方法无法在日光场景下表现很差。
		3.单目SLAM无法获得绝对尺度，会存在尺度漂移现象。若无法获得绝对尺度，则在VR/AR和机器人应用中都会遇到很大问题。
		4.单目SLAM无法在纯旋转情况下工作，因为此时的stereo-baseline丢失，无法进行立体估计。
	近来，通过机器学习方法基于单幅图像估计场景深度的研究取得了新进展。其中，深度卷积神经网络(CNN)表现出色。其优点是可以得到高分辨的、绝对尺度的深度估计图，甚至在特征点稀疏或repetitive patterns的情况下也表现出色。由于场景的绝对深度可以通过样本训练学习得到，因此不需要基于场景的模型假设，也不需要几何上的约束。然而，此方法的缺陷是虽然深度预测在全局上是准确的，但在深度图中物体的边界处是局部模糊的，这样会丧失物体深度、形状的细节信息。
	我们提出该方法的主要思想是：将深度估计和单目SLAM结合。为了解决深度图中的模糊边缘问题(blurred depth borders)，我们将CNN预测的深度图作为稠密重建的初始猜测(initial guess)，并连续地通过直接法SLAM来优化（依靠small-baseline stereo matching，该方法和参考文献【4】的LSD-SLAM相似，LSD-SLAM是典型的直接法)。非常重要的一点是，small-baseline stereo matching拥有可以改善边缘区域深度估计的潜力。与此同时，CNN预测的深度图有绝对尺度，可为位姿估计提供更多约束条件，显著提高了位姿估计、路径和重建场景的精度。而且由于本方法可克服纯旋转等恶劣情况，因此tracking的稳定性大大增强。另外，该框架可在PC上实时运行，CPU和GPU同时运算，用GPU来执行CNN的深度估计，用CPU来执行深度优化。
	除可用于深度估计之外，CNN还可成功地用于其他高维回归(high-dimension regression)的任务，其中一个典型的例子就是语义分割(semantic segmentation)。我们基于这种方法提出了CNN-SLAM的扩展版本，即用pixel-wise labels将语义labels和稠密SLAM准确一致且高效率地融合在一起。

【相关研究工作】
	SLAM按传感器分可分为基于深度相机的和基于单目相机的，按方法分可分为直接法和特征点法。
	对于单目SLAM，ORB可以说是state-of-the-art的。
	由于深度学习的发展，从单视角进行深度估计的研究得到了越来越多的重视。
